# ğŸ§  AI Review & Data Analyst (RAG + Fraud Detection)

An end-to-end **Streamlit-based AI dashboard** that performs:

* Fake / suspicious review detection
* Product-level risk analysis
* Retrieval-Augmented Generation (RAG) over tabular data
* Natural language Q&A using **Groq LLM (LLaMA 3.3)**

This tool is designed for **review integrity analysis**, **fraud detection**, and **AI-assisted data exploration**.

---

## ğŸš€ Features

### ğŸ“‚ Data Ingestion

* Upload any CSV file
* Automatic column detection (product, review, rating, date)
* Manual column override via sidebar

### ğŸ•µï¸ Fake Review Detection

* Weakly supervised ML pipeline
* TF-IDF + RandomForest classifier
* Auto-generates `is_suspicious` column

### ğŸ“Š Analytics Dashboard

* Integrity score (gauge)
* Total vs suspicious records
* Product-level risk percentage table

### ğŸ§  AI Chat (RAG)

* Builds a vector index using **ChromaDB**
* SentenceTransformer embeddings (`all-MiniLM-L6-v2`)
* Ask natural language questions about your dataset
* Responses generated via **Groq LLaMA 3.3 (70B)**

### ğŸ” Safe Vector Storage

* Dataset-based hashing to avoid collisions
* Session-persistent vector collections

---

## ğŸ§° Tech Stack

| Layer         | Technology           |
| ------------- | -------------------- |
| UI            | Streamlit            |
| ML            | Scikit-learn         |
| Vector DB     | ChromaDB             |
| Embeddings    | SentenceTransformers |
| LLM           | Groq (LLaMA 3.3 70B) |
| Visualization | Plotly               |

---

## ğŸ“¦ Installation

```bash
pip install streamlit pandas plotly scikit-learn chromadb sentence-transformers langchain-groq
```

---

## ğŸ”‘ Environment Setup

### Streamlit Secrets

Create a `.streamlit/secrets.toml` file:

```toml
GROQ_API_KEY = "your_groq_api_key_here"
```

---

## â–¶ï¸ Run the App

```bash
streamlit run app.py
```

---

## ğŸ§  How It Works

### 1ï¸âƒ£ Column Auto-Detection

Uses keyword matching to detect:

* Product name
* Review text
* Rating
* Date

### 2ï¸âƒ£ Weak Supervision

Reviews are weakly labeled using keyword frequency:

* "best", "excellent", "awesome", "fake", "scam", "worst"

These labels train a RandomForest classifier to detect suspicious reviews.

### 3ï¸âƒ£ Risk Metrics

* **Integrity Score** = % of non-suspicious reviews
* Product-level risk % computed via group-by

### 4ï¸âƒ£ RAG Pipeline

* Text columns are embedded
* Stored in ChromaDB
* Top-K relevant rows retrieved
* Context passed to Groq LLM for reasoning

---

## ğŸ’¬ Example Questions

* "Which products have the highest fraud risk?"
* "Summarize customer sentiment"
* "Are there spikes in suspicious reviews?"
* "Which product has the worst integrity score?"

---

## ğŸ“ Project Structure

```text
app.py
.streamlit/
  â””â”€â”€ secrets.toml
```

---

## âš ï¸ Limitations

* Weak supervision â‰  ground truth
* Best suited for exploratory analysis
* Not a replacement for human moderation

---

## ğŸ”® Future Improvements

* Advanced NLP fraud models
* Time-series anomaly detection
* Review sentiment + emotion analysis
* User authentication
* Persistent vector storage (DuckDB / S3)

---

## ğŸ‘¨â€ğŸ’» Author

Built for **AI-driven review integrity & data intelligence** use cases.

---

## ğŸ“œ License

MIT License
